{
# "face_size": (en píxels)
# tamaño mínimo de la cara para procesar la cara detectada
# de momento dependerá de la resolución del vídeo
# 20 píxeles podría ser lo adecuado si la camara está muy alta como el lobby de LedBar hay que bajarlo
"face_size": 20,

# "face_threshold" = (0,5-1)
# calidad cara detectada 
# es el threshold del detector de caras
# si aparecen detecciones extrañas, puede ser que el valor sea demasiado bajo
"face_threshold" = 0.6,

# cosine_threshold" = (0-1)
# distancia euclidiana entre los embeddings de las caras detectadas
# según https://github.com/serengil/deepface/blob/master/deepface/commons/distance.py,
# el valor debería ser 0.67 para ARCFace pero con las máscaras del COVID debemos reducirlo a 0.63
# si se detecta demasiadas veces a una misma persona debemos aumentarlo de 0.01 en 0.01
"cosine_threshold" = 0.63,

# "embedding_threshold" (14-20)
# cantidad de info que contiene el embedding de 512 bytes, comprimimos las caras con el modelo ARCFace
# lo sugerido por los autores del código es mayor de 17 pero con máscaras debemos reducirlo a 16 o menos
# mejores caras mejores resultados del reconocedor de personas
"embedding_threshold" = 16,

# roi de la camara, zona a controlar las caras
"Y_start" = 300,
"Y_end" = 1000,
"X_start" = 100,
"X_end" = 1300, 

# "tiempo_estancia_clientes" = (en segundos) 
# Segundos en los que se envían al webservice todos los IDs de personas recogidos
# También se borran los IDs del buffer para que no se llenen de embeddings ya conocidos
"tiempo_estancia_clientes": 180
}